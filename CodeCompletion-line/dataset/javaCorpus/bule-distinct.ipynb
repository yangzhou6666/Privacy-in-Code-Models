{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu,SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_path = '/workspace/Privacy-in-Code-Models/CodeCompletion-line/dataset/javaCorpus/CodeGPT-small-java/20/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'CodeGPT-small-java-adaptedGPT2_victim_K_10_T_1.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_label_0 = []\n",
    "# with open (os.path.join(prefix_path,'test_victim.json'),'r') as f:\n",
    "#     for line in f:\n",
    "#         gt = json.loads(line)\n",
    "#         gt_label_0.append(gt['gt'].strip().split(' '))\n",
    "\n",
    "# gt_label_1 = []\n",
    "# with open (os.path.join(prefix_path,'train_victim.json'),'r') as f:\n",
    "#     for line in f:\n",
    "#         gt = json.loads(line)\n",
    "#         gt_label_1.append(gt['gt'].strip().split(' '))\n",
    "\n",
    "gt_label_0 = []\n",
    "with open(os.path.join(prefix_path,f'test_victim_infer.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        gt_label_0.append(line.strip().split(\" \"))\n",
    "gt_label_1 = []\n",
    "with open(os.path.join(prefix_path,f'train_victim_infer.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        gt_label_1.append(line.strip().split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_0 = []\n",
    "with open(os.path.join(prefix_path,f'test_{suffix}_infer.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        candidate_0.append(line.strip().split(\" \"))\n",
    "candidate_1 = []\n",
    "with open(os.path.join(prefix_path,f'train_{suffix}_infer.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        candidate_1.append(line.strip().split(\" \"))\n",
    "\n",
    "# candidate_0 = []\n",
    "# with open (os.path.join(prefix_path,'test_victim.json'),'r') as f:\n",
    "#     for line in f:\n",
    "#         gt = json.loads(line)\n",
    "#         candidate_0.append(gt['gt'].strip().split(' '))\n",
    "\n",
    "# candidate_1 = []\n",
    "# with open (os.path.join(prefix_path,'train_victim.json'),'r') as f:\n",
    "#     for line in f:\n",
    "#         gt = json.loads(line)\n",
    "#         candidate_1.append(gt['gt'].strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4854247035083273\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "for i,(c,r) in enumerate(zip(candidate_0+candidate_1,gt_label_0+gt_label_1)):\n",
    "    reference = [r]\n",
    "    candidate = c\n",
    "    total_score += sentence_bleu(reference, candidate, weights=(1/4,1/4, 1/4, 1/4),smoothing_function=smoothie)\n",
    "print(total_score/len((candidate_0)*2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
